{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "alIIEHibGc3M"
      },
      "source": [
        "## Part 1: Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 325
        },
        "id": "6eDUJ4NtGc3P",
        "outputId": "2480098c-135c-4cbf-9552-018494ee8ff5"
      },
      "outputs": [],
      "source": [
        "# Import our dependencies\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.layers import Dense, Input, concatenate\n",
        "\n",
        "#  Import and read the attrition data\n",
        "attrition_df = pd.read_csv('https://static.bc-edx.com/ai/ail-v-1-0/m19/lms/datasets/attrition.csv')\n",
        "attrition_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g22aQSY4Gc3Q",
        "outputId": "1f5c13c1-b981-4e40-a7ed-dd3fe6f1b81e"
      },
      "outputs": [],
      "source": [
        "# Determine the number of unique values in each column.\n",
        "attrition_df.nunique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "50vMgBEnJbfM"
      },
      "outputs": [],
      "source": [
        "# Create y_df with the Attrition and Department columns\n",
        "y_df = attrition_df[['Attrition', 'Department']]\n",
        "\n",
        "# Display the first few rows of y_df\n",
        "print(y_df.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Virka0zLGc3R",
        "outputId": "dd5aee3a-9458-4ba6-e857-1b234de40915"
      },
      "outputs": [],
      "source": [
        "# Create a list of at least 10 column names to use as X data\n",
        "X_columns = ['Education', 'Age', 'DistanceFromHome', 'JobSatisfaction', 'PercentSalaryHike', \n",
        "             'StockOptionLevel', 'WorkLifeBalance', 'YearsAtCompany', 'YearsSinceLastPromotion', \n",
        "             'NumCompaniesWorked']\n",
        "\n",
        "\n",
        "# Create X_df using your selected columns\n",
        "X_df = attrition_df[X_columns]\n",
        "\n",
        "\n",
        "# Show the data types for X_df\n",
        "\n",
        "print(X_df.dtypes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KaJfdOGUMHMR"
      },
      "outputs": [],
      "source": [
        "# Split the data into training and testing sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_df, y_df, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NYubUJqiLCSp",
        "outputId": "53f31721-571c-4c94-d13e-25a715749593"
      },
      "outputs": [],
      "source": [
        "# Convert your X data to numeric data types however you see fit\n",
        "# Add new code cells as necessary\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EWA-aIA5Gc3T"
      },
      "outputs": [],
      "source": [
        "# Create a StandardScaler\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# Fit the StandardScaler to the training data\n",
        "scaler.fit(X_train)\n",
        "\n",
        "# Scale the training data\n",
        "X_train_scaled = scaler.transform(X_train)\n",
        "\n",
        "# Scale the testing data using the same scaler\n",
        "X_test_scaled = scaler.transform(X_test)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-z0Mky8vQSz4",
        "outputId": "debefc85-c20b-48f5-f4d9-91eadd65d36a"
      },
      "outputs": [],
      "source": [
        "# Create a OneHotEncoder for the Department column\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "encoder = OneHotEncoder()\n",
        "# Fit the encoder to the training data\n",
        "encoder.fit(y_train[['Department']])\n",
        "\n",
        "# Create two new variables by applying the encoder\n",
        "# to the training and testing data\n",
        "department_train_encoded = encoder.transform(y_train[['Department']])\n",
        "department_test_encoded = encoder.transform(y_test[['Department']])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-G4DSpvFRrk4",
        "outputId": "9842e948-8a55-4b80-8fac-f96714e85589"
      },
      "outputs": [],
      "source": [
        "# Create a OneHotEncoder for the Attrition column\n",
        "attrition_encoder = OneHotEncoder()\n",
        "\n",
        "# Fit the encoder to the training data\n",
        "attrition_encoder.fit(y_train[['Attrition']])\n",
        "\n",
        "# Create two new variables by applying the encoder\n",
        "# to the training and testing data\n",
        "attrition_train_encoded = attrition_encoder.transform(y_train[['Attrition']])\n",
        "attrition_test_encoded = attrition_encoder.transform(y_test[['Attrition']])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ykNmu_WWGc3T"
      },
      "source": [
        "## Create, Compile, and Train the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WUptZqmSGc3T"
      },
      "outputs": [],
      "source": [
        "# Find the number of columns in the X training data\n",
        "num_columns = X_train_scaled.shape[1]\n",
        "print(\"Number of columns in the X training data:\", num_columns)\n",
        "\n",
        "# Create the input layer\n",
        "input_layer = Input(shape=(num_columns,))\n",
        "\n",
        "# Create at least two shared layers\n",
        "shared_layer1 = Dense(64, activation='relu')\n",
        "shared_layer2 = Dense(32, activation='relu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JukjTm2yTEqd"
      },
      "outputs": [],
      "source": [
        "# Create a branch for Department\n",
        "# with a hidden layer and an output layer\n",
        "\n",
        "# Create the hidden layer\n",
        "department_hidden_layer = Dense(64, activation='relu')(input_layer)\n",
        "\n",
        "# Create the output layer\n",
        "department_output_layer = Dense(2, activation='softmax', name='department_output')(department_hidden_layer)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9OqhUiOJUBkR"
      },
      "outputs": [],
      "source": [
        "# Create a branch for Attrition\n",
        "# with a hidden layer and an output layer\n",
        "\n",
        "# Create the hidden layer\n",
        "attrition_hidden_layer = Dense(64, activation='relu')(input_layer)\n",
        "\n",
        "# Create the output layer\n",
        "attrition_output_layer = Dense(3, activation='softmax', name='attrition_output')(attrition_hidden_layer)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "twmuejdxGc3T",
        "outputId": "25096308-b68b-42e4-e4ea-ae82e97c435a"
      },
      "outputs": [],
      "source": [
        "# Create the model\n",
        "model = Model(inputs=input_layer, outputs=[department_output_layer, attrition_output_layer])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Summarize the model\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c8oGy0dpGc3U",
        "outputId": "cc667d43-28cf-42d4-d719-c2bc02888d30"
      },
      "outputs": [],
      "source": [
        "# Train the model\n",
        "\n",
        "history = model.fit(X_train_scaled, [department_train_encoded.toarray(), attrition_train_encoded.toarray()], \n",
        "                    validation_data=(X_test_scaled, [department_test_encoded.toarray(), attrition_test_encoded.toarray()]), \n",
        "                    epochs=10, batch_size=32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VsMoaQlgGc3U",
        "outputId": "1bd4e601-e964-4abc-ad83-aeecf6b696be"
      },
      "outputs": [],
      "source": [
        "# Evaluate the model with the testing data\n",
        "evaluation = model.evaluate(X_test_scaled, [department_test_encoded.toarray(), attrition_test_encoded.toarray()])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZlCtlHi0Vt54",
        "outputId": "bc21ef3e-80c2-4b38-9c29-79515bc23dec"
      },
      "outputs": [],
      "source": [
        "# Print the accuracy for both department and attrition\n",
        "evaluation = model.evaluate(X_test_scaled, [department_test_encoded.toarray(), attrition_test_encoded.toarray()])\n",
        "\n",
        "department_accuracy = evaluation[1]\n",
        "attrition_accuracy = evaluation[2]\n",
        "\n",
        "# Print the accuracy for both department and attrition\n",
        "print(\"Department Accuracy:\", department_accuracy)\n",
        "print(\"Attrition Accuracy:\", attrition_accuracy)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eGSyfsZfWOQM"
      },
      "source": [
        "# Summary\n",
        "\n",
        "In the provided space below, briefly answer the following questions.\n",
        "\n",
        "1. Is accuracy the best metric to use on this data? Why or why not?\n",
        "\n",
        "2. What activation functions did you choose for your output layers, and why?\n",
        "\n",
        "3. Can you name a few ways that this model might be improved?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pi9SLpFnWvbF"
      },
      "source": [
        "YOUR ANSWERS HERE\n",
        "\n",
        "1. \n",
        "2. \n",
        "3. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    },
    "vscode": {
      "interpreter": {
        "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
